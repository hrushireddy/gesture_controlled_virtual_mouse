
# üñ±Ô∏è Virtual Mouse with Voice Assistant and Gesture Recognition

This project enables users to control a computer mouse using **hand gestures** and perform various system actions through **voice commands**. Built using Python, OpenCV, and speech recognition libraries, this tool enhances accessibility and enables hands-free interaction with your system.

---

## üîß Features

- üëã **Gesture Recognition**  
  - Move cursor using hand tracking  
  - Perform left-click, right-click, double-click  
  - Scroll and screen positioning

- üéôÔ∏è **Voice Assistant Integration**  
  - Open apps (Notepad, browser, etc.)  
  - Tell jokes, show weather, give news updates  
  - System control via speech commands

- üß† **Computer Vision + NLP combo**  
  - Real-time webcam feed analysis  
  - Voice command recognition using Google API

---

## üß† Technologies Used

- Python 3.7+
- OpenCV
- NumPy
- PyAutoGUI
- SpeechRecognition
- pyttsx3
- Google Speech API
- Windows OS

---

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄsrc
  ‚îú‚îÄ‚îÄ Gesture_Controller.py       # Hand tracking & virtual mouse control
  ‚îú‚îÄ‚îÄ Voice_Assistant.py          # Voice-based command executor
  ‚îú‚îÄ‚îÄ app.py                      # ChatBot script/UI interaction
  ‚îú‚îÄ‚îÄ calib_images/               # Camera calibration files (checkerboard)
  ‚îú‚îÄ‚îÄ requirements.txt            # Required Python packages
‚îî‚îÄ‚îÄ README.md                   # This file
```

---

## üß™ Setup Instructions (Windows)

### 1. Clone the Repository
```bash
git clone https://github.com/hrushireddy/virtual-mouse-voice
cd virtual-mouse-voice
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

If `requirements.txt` is missing, install manually:
```bash
pip install opencv-python pyttsx3 SpeechRecognition pyautogui numpy
```

### 3. Run the Application
```bash
python Voice_Assistant.py
```

Make sure your **webcam and microphone** are enabled and functional.

> To exit the webcam stream, press `q` in the OpenCV window.

---

## üéØ Use Cases

- Accessibility for users with limited mobility
- Hands-free interaction for hygienic environments
- Smart automation demo for academic projects

---

## üîÆ Future Improvements

- Add more complex gesture patterns
- Improve gesture stability with MediaPipe
- Build GUI for feedback and status display
- Add multi-language voice support
- Enable browser automation and email features

---

## üìú License

This project is licensed under the **MIT License**. You are free to use, modify, and share it with attribution.

---

## üë®‚Äçüíª Author

**Mareddi Hrushikesh Reddy**  
B.Tech CSE Student | Python & AI Enthusiast | Open Source Explorer  
üîó GitHub: [@hrushireddy](https://github.com/hrushireddy)  
üîó LinkedIn: [Hrushikesh Mareddi](https://www.linkedin.com/in/hrushikesh-mareddi-095952281/)

---

> If you like this project, feel free to ‚≠ê the repo or fork it!
